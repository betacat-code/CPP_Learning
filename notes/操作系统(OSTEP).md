# 第一章 虚拟化CPU
## 1.1 进程
进程就是运行中的程序。程序本身只是磁盘上的一些代码和静态数据，是操作系统把其加载到内存中并设置好内存和CPU使得程序可以运行。我们的终极目标是让多个程序并发运行，这就需要虚拟化CPU，机制是分时复用CPU。要实现分时复用CPU，就要实现进程的切换，即上下文切换。另外还需要有调度算法来确定接下来切换到哪一个进程来运行。

程序的指令和静态数据最初都在磁盘上，首先需要将其读入内存中，但现代操作系统惰性（lazily）执行该过程，即仅在程序执行期间需要加载的代码或数据片段，才会加载。

将代码和静态数据加载到内存后，操作系统在运行此进程之前还需要执行其他一些操作。必须为程序的运行时栈（run-time stack 或 stack）分配一些内存。程序使用栈存放局部变量、函数参数和返回地址。操作系统分配这些内存，并提供给进程。

操作系统也可能会用参数初始化栈。具体来说，它会将参数填入 main()函数，即 argc 和 argv数组。

操作系统也可能为程序的堆（heap）分配一些内存。在 C 程序中，堆用于显式请求的动态分配数据。程序通过调用 malloc()来请求这样的空间，并通过调用 free()来明确地释放
它。

## 1.2 机制：受限直接执行

直接执行部分很简单：只需直接在CPU上运行程序即可。因此，当OS希望启动程序运行时，它会在进程列表中为其创建一个进程条目，为其分配一些内存，将程序代码（从磁盘）加载到内存中，找到入口点（main()函数或类似的），跳转到那里，并开始运行用户的代码。
这种方法在我们虚拟化CPU时产生了一些问题。

- 第一个问题：如果我们只运行一个程序，操作系统怎么能确保程序只做我们允许它做的事情，同时仍然高效地运行它？

- 第二个问题：当我们运行一个进程时，操作系统如何让它停下来并切换到另一个进程，从而实现虚拟化CPU所需的时分共享？

### 对于问题1：
引入一种新的处理器模式，称为用户模式（user mode）。在用户模式下运行的代码会受到限制。例如，在用户模式下运行时，进程不能发出I/O请求。这样做会导致处理器引发异常，操作系统可能会终止进程。与用户模式不同的内核模式（kernel mode），操作系统（或内核）就以这种模式运行。在此模式下，运行的代码可以做任何它喜欢的事，包括特权操作，如发出I/O请求和执行所有类型的受限指令。

要执行系统调用，程序必须执行特殊的陷阱（trap）指令,该指令同时跳入内核并将特权级别提升到内核模式。一旦进入内核，系统就可以执行任何需要的特权操作（如果允许），从而为调用进程执行所需的工作。完成后，操作系统调用一个特殊的从陷阱返回（return-from-trap）指令

### 对于问题2：操作系统如何重新获取CPU的控制权？

利用时钟中断重新获得控制权 时钟设备可以编程为每隔几毫秒产生一次中断。产生中断时，当前正在运行的进程停止，操作系统中预先配置的中断处理程序（interrupt handler）会运行。此时，操作系统重新获得CPU的控制权。

### 保存和恢复上下文
为当前正在执行的进程保存一些寄存器的值（保存到它的内核栈），并为即将执行的进程恢复一些寄存器的值（从它的内核栈取出）。

这样一来，操作系统就可以确保最后执行从陷阱返回指令时，不是返回到之前运行的进程，而是继续执行另一个进程。

## 1.3 进程调度
- 周转时间：一个进程从提交到运行结束的总时间
- 相应时间：一个进程从提交到首次开始运行的时间

### 多级反馈队列：MLFQ

其尝试用历史预测未来。它在运行过程中，根据已经观察到的行为来调整进程的优先级等，从而利用反馈的信息来适应当前情况。
- 设置多个不同优先级的队列，优先运行高优先级队列中的进程。
- 进程提交到系统后，首先放在最高优先级队列中。一个队列中采用轮询调度(Round-Robin)算法来运行。
- 每个队列都有一个时间配额属性，一个进程用完了这个队列规定的时间后就要降到低一级队列。
- 每经过一段时间就要把所有进程重新加入最高级队列。

对于短进程，其可以在较高优先级的队列中较快完成。对于长进程，周期性地把所有进程重新加入最高级队列使其不至于饿死。并且对于不同时间段行为不同的进程，也可以根据其行为来合理地调度它。

MLFQ依然有一些问题，最大的问题是如何配置MLFQ。设置多少队列？每一个队列的RR算法的时间片以及时间配额是多少？提高所有进程优先级的周期是多少？这些问题没有确切答案，可能做就是在运行过程中动态调整来取得平衡。但是让系统自己去学习一个好的参数也不容易，因此我们会有一个包含默认值的配置文件，并且用户可以给出建议从而利于OS动态调整参数。

## 1.4 多处理器调度

多核处理器由于有多个CPU核，而每个CPU都有自己的cache，因此存在一个多核CPU的cache一致性问题。基本解决方法是使用总线，每个CPU都监听其他CPU和内存的操作，如果发现对自己缓存中同一内存地址的数据的更新，就作废cache中的数据（valid设为0）或者直接进行更新。

另外对于多核CPU，并发问题是绕不开的，需要加锁解锁，但高锁争用会导致并行性很差。

cache亲和性：一个进程在一个CPU核上运行时，会在该CPU的cache、TLB、分支预测器等硬件上维护很多状态。如果把一个进程尽量调度到同一个CPU核上，会由于这些缓存中的数据从而运行更快。多处理器调度应该考虑到cache亲和性。

调度策略上，最简单的是复用单核调度：为所有CPU核维护一个队列即可，每个CPU核空闲时都从队列头取出一个进程来运行。其最大优点是简单，但是由于多核并行访问因此需要锁来保证原子性，这就会带来性能损失。还有问题就是cache亲和性，每个CPU核都简单地从队列中取出一个进程来运行，因此每个进程都可能会在不同CPU间迁移，从而不利于cache亲和性。

可以采用多队列调度，为每个CPU维护一个队列。这样锁争用和cache亲和性都不再是问题，但会产生一个问题就是工作负载的分配。例如一个新提交的进程应该加入哪个队列，以及更重要的是如果两个队列的工作负载情况差异较大，应该怎么样实现负载均衡？目前无共识答案。

# 第二章 虚拟化内存

## 2.1 地址转换
在虚拟化CPU时使用的机制是受限直接访问。就是让用户程序的大部分指令直接使用硬件CPU和内存，仅在一些关键时间点时OS介入。

那么在虚拟化内存时使用的机制是地址转换。用户级程序中的地址全是其虚拟地址空间中的虚拟地址，其在访存时会被专门硬件和操作系统合作翻译成物理地址，从而得到内容。

CPU 需要两个硬件寄存器：基址（base）寄存器和界限（bound）寄存器，有时称为限制（limit）寄存器。界限寄存器提供了访问保护。如果进程需要访问超过这个界限或者为负数的虚拟地址，CPU 将触发异常，进程最终可能被终止。

<code>
physical address = virtual address + base
</code>

## 2.2 分段

如何支持稀疏地址空间？

泛化基址+界限这个概念，为地址空间中的每个段设置一个基址+界限。比如代码、堆、栈段。这样已使用的内存才会真正分配物理内存。

硬件在地址转换时使用段寄存器。它如何知道段内的偏移量，以及地址引用了哪个段？

- 显式方式，就是用虚拟地址的开头几位来标识不同的段
- 隐式方式中，硬件通过地址产生的方式来确定段

分段也带来了一些新的问题：物理内存很快充满了许多空闲空间的小洞，因而很难分配给新的段，或扩大已有的段。这种问题被称为外部碎片。

## 2.3 分页

分段会产生外部碎片，因此可以考虑分页，把虚拟地址空间分割成固定大小的单元，每个单元就是页。而物理内存中的一个页称为一个页帧。为了追踪每个页对应的物理页帧，OS为每个进程维护一个页表。

虚拟地址分为虚拟页号VPN和页内偏移offset，地址翻译的流程就是根据页表查找VPN(virtual page number)对应的物理页号PPN(physical page number)，找到对应的物理页帧，并根据offset找到所需字节。页表比较巨大，因此我们将其存在物理内存中，而不是内存中。

页表就是一种数据结构，用于将虚拟地址（或者实际上，
是虚拟页号）映射到物理地址（物理帧号）最简单的形式称为线性页表，就是一个数组。操作系统通过虚拟页号检索该数组，并在该索引处查找页表项，以便找到期望的物理帧号。

页表项（PTE）中还有一些标志位、例如有效位、保护位rwx、访问位、修改位等。

## 2.4 快速地址转换:TLB

TLB缓存最近使用的VPN到PPN的映射。TLB作为一种缓存，其基本访问原理和cache一样，TLB命中就直接得到PPN，未命中就需要访问页表得到PPN并更新TLB。其能有效的原理是局部性。

TLB作为一种缓存，其是全相联的。因为TLB未命中的开销很大，要采用全相联来尽可能命中。主要策略有LRU和随机。

TLB在进程切换时会有问题，上一个进程的TLB内容对于下一个进程来说是无意义的。为此可以把TLB全部有效位都置为0。但是上一个进程再次运行时性能就会降低，在频繁进程切换之下总体性能会很低。

为了减少这种开销，一些系统增加了硬件支持，实现跨上下文切换的 TLB 共享。有了地址空间标识符，TLB 可以同时缓存不同进程的地址空间映射。

## 2.5 多级页表

多级页表的基本思想：将页表分成页大小的单元。如果整页的页表项（PTE）无效，就完全不分配该页的页表。为了追踪页表的页是否有效（以及如果有效，它在内存中的位置），使用了名为页目录（page directory）的新结构。

多级页表大大节省了空间，但其并非没有缺点，实际上它是一个时间——空间的折中。TLB未命中时，访存次数相比线性页表还会增加。

>在构建数据结构时，应始终考虑时间和空间的折中
(time-space trade-off)。通常，如果你希望更快地访问特定的数据结构，就必须为该结构付出空间的代价。

使用多级页表的地址翻译会将原来的VPN拆成几个小的VPN，分别用于在不同级页表中索引PTE。最高级页表的物理地址由OS为每个进程在一个寄存器中维护，进程切换时会保存并恢复该寄存器以切换地址空间。

## 2.6 虚拟内存

使用物理内存+磁盘为进程支持巨大的虚拟内存空间。页可以在内存和磁盘间交换。之前如果一个进程产生对应的PTE无效的虚拟地址，这个进程也许会被直接kill。

但现在，进程访问的可能是不在物理内存中而是在磁盘中的页。这样产生了page fault，进程会trap进内核中的page fault handler来处理缺页。OS会根据PTE中存储的磁盘地址信息来发起磁盘I/O，然后更新PTE中的PPN和有效位，为了方便起见同时也会更新TLB中的PPN和有效位，最后重新执行产生page fault的指令。如果访问不合法的页就会提示“段错误”，进程被直接kill。

在真实系统中，空闲页帧数少于某个警戒线时，后台的一个页守护进程就会运行，驱逐出一定数目的页帧。由于磁盘I/O的开销非常大，因此我们需要尽可能避免缺页。

近似LRU是现代OS采用的方法。硬件为每个页维护一个访问位，通常在这个页对应的PTE的标志位中。这个页被访问时（读或写）硬件将其置1.只有OS才可以将其置0。

每个页都在一个逻辑上的环形列表里，指针最初始指向某个页，当开始进行页替换时，开始扫描每个页的访问位，若其为1，说明最近被访问过，不适合驱逐，将其置为0，扫描下一个，直到扫描到一个本来就是0的，将其驱逐。

这被称为CLOCK算法。其可以考虑页是否被写入过，利用PTE中的脏位，优先驱逐没有被写入过的。注意可能会扫描到访问位为0而修改位为1的情况，这种页是之前访问过，访问位为1，但是被上一次CLOCK算法扫描之后设为了0，并且在两次扫描之间没有被访问过。

页面驱逐优先级是：(访问位，修改位)，(0，0)>(0，1)>(1，0)>(1，1)。

页面替换只是虚拟内存中的一个策略。对应的还有页面读取，通常使用请求分页，即一个页面真正被访问时才加载进内存，并且可以预取页面。以及将页面写入磁盘的策略，一次写一个可以但效率低，通常分组写入效率更高。

# 第三章 并发
## 3.1 多线程

线程是轻量级的进程，多线程程序会有多个执行点（多个程序计数器，每个都用于取指令和执行），共享地址空间。

线程运行顺序具有不确定性，它们在访问共享数据时可能会产生一些错误结果。其根源是进程调度不可控，并发的不确定性。不可控的调度会导致线程以错误顺序访问临界区。

对临界区的访问应该是互斥的，不能由多线程同时执行。解决这个问题实际上是确保对临界区访问的原子性，防止执行一部分而破坏一致性。可以用锁来解决，进入临界区前必须持有对应的锁，执行完之后释放锁，锁在某一时刻最多只能被一个进程持有。这是互斥问题。

多线程中还有同步问题，即一个线程需要等待另一个线程完成某些操作才能继续执行。我们可以使用条件变量来实现wait/signal机制，线程之间可以通过条件变量来通信。而信号量是一种较强的机制，互斥和同步它都可以解决。

## 3.2 锁

锁保证了临界区的原子性。锁让程序员获得一些线程调度的控制权，可以保证临界区内只有一个活跃线程。mutex的意义就是互斥。

<code>lock()</code>和 <code>unlock()</code>函数的语义很简单。调用 <code>lock()</code>尝试获取锁，如果没有其他线程持有锁，该线程会获得锁，进入临界区。这个线程有时被称为锁的持有者。如果另外一个线程对相同的锁变量调用 <code>lock()</code>，因为锁被另一线程持有，该调用不会返回。这样，当持有锁的线程在临界区时，其他线程就无法进入临界区。


锁的持有者一旦调用 <code>unlock()</code>，锁就变成可用了。如果没有其他等待线程（即没有其他线程调用过 <code>lock()</code>并卡在那里），锁的状态就变成可用了。如果有等待线程（卡在 <code>lock()</code>里），其中一个会（最终）注意到（或收到通知）锁状态的变化，获取该锁，进入临界区。

## 3.3 条件变量

很多情况下线程需要等到某一条件满足后才能继续运行。若不满足就简单自旋会浪费时间片，我们期望让它休眠，进入阻塞态，直到等待的条件满足后进入就绪态。如何等待？我们可以使用条件变量来提供支持的同步协议。它有wait和signal两个操作。一个条件变量和一个锁相关联。

一个线程通常会先持有锁，通过while而不是if来检查状态变量是否满足，若不满足就使用wait在这个条件变量上sleep。成功调用wait会首先释放锁，直到状态满足，线程wake时会重新持有锁，进行后续操作并释放锁。调用wait和signal时都要持有条件变量的锁，并且一个状态变量是有必要的，这都是为了防止一个线程可能无法被唤醒。

    int done = 0;
    pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;
    pthread_cond_t c = PTHREAD_COND_INITIALIZER;
    void thr_exit() {
        Pthread_mutex_lock(&m);
        done = 1;
        Pthread_cond_signal(&c);
        Pthread_mutex_unlock(&m);
    }
    void *child(void *arg) {
        printf("child\n");
        thr_exit();//退出
        return NULL;
    }
    void thr_join() {
        Pthread_mutex_lock(&m);
        while (done == 0)//必须通过while
            Pthread_cond_wait(&c, &m);
        Pthread_mutex_unlock(&m);
    }

## 3.4 信号量
信号量是有一个整数值的对象，可以用两个函数来操作它。在 POSIX 标准中，是<code>sem_wait()</code>和 <code>sem_post()</code>

    include <semaphore.h>
    sem_t s;
    sem_init(&s, 0, 1);
    
其中申明了一个信号量 s，通过第三个参数，将它的值初始化为 1。第二个参数，在我们看到的所有例子中都设置为 0，表示信号量是在同一进程的多个线程共享的。

首先，<code>sem_wait()</code>要么立刻返回（调用时，信号量的值大于等于 1），要么会让调用线程挂起，直到之后的一个 post 操作。可能多个调用线程都调用 <code>sem_wait()</code>，因此都在队列中等待被唤醒。

<code>sem_post()</code>并没有等待某些条件满足。它直接增加信号量的值，如果有等待线程，唤醒其中一个。最后，当信号量的值为负数时，这个值就是等待线程的个数。

## 3.5 死锁

并发编程容易出问题。比如未使用锁导致临界区的不互斥访问，违反了原子性，又如未使用条件变量导致线程间的不恰当时序关系。实际上绝大多数bug都是这两种。

此外就是死锁，如果要同时获得多个锁，就要小心死锁。死锁的产生需要四个必要条件：

- 互斥访问，线程对资源的访问是互斥的
- 持有并等待，线程持有某些资源，然后继续等待其他所需资源
- 循环等待，线程的等待链条形成一个环
- 非抢占，不能抢占其他线程的资源

死锁预防：破坏死锁的四个必要条件之一。最常用的是避免循环等待，规定抢占锁的顺序，但要对锁的作用有深入了解。然后是避免持有并等待，线程一下子获得所有资源后才开始运行，但会降低并发性和资源利用率。接着是避免非抢占，就是线程可以去抢其他线程的资源，但可能会产生线程互相抢来抢去一个资源从而导致活锁。最后就是避免互斥，这个是最难的。

>实际系统中都是采用最简单的，允许死锁发生，当发生时我们可以采取一些行动来处理（例如重启），或者是干脆就不管。很多数据库系统使用了死锁检测和恢复技术。死锁检测器会定期运行，通过构建资源图来检查循环。

## 3.6 基于事件的并发


多线程只是用来实现并发的一种方式。在GUI应用和某些服务器中使用的是event-based concurrency，例如Node.js。多线程中，并发的正确实现非常有难度，且对于并发线程的调度无法控制。

事件驱动的并发就是等待某些事件的发生（例如点击鼠标、网络数据包到来），将其添加进队列，然后主程序就处理这些事件。这样调度就完全可控，且一次处理一个事件，不需要锁。得知某些事件的发生，即接收事件，可以使用Linux的select或poll系统调用。

但有一个重要问题是我们不能阻塞主程序，例如发起磁盘I/O。在多线程中这不是问题，但在事件驱动中我们没有其他线程，只是main event的loop。一个阻塞的调用就会阻塞整个服务器，这会造成资源的极大浪费和性能的极大损失。

为此我们可以使用异步I/O，其相当于只是发送一个请求I/O的信号，若发送成功之后会立即返回去处理其他事件。如果不使用异步I/O，纯事件驱动的方法是无法工作的。但也可以采取一些混合方法，如使用线程池来管理I/O。

# 第四章 I/O设备

